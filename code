#Imports
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import tensorflow_datasets as tfds
from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, InputLayer, BatchNormalization
from tensorflow.keras.losses import BinaryCrossentropy
from tensorflow.keras.optimizers import Adam 
from tensorflow.keras.metrics import Accuracy


# Importing our dataset from tensorflow datasets

from tensorflow_datasets.core import dataset_info
dataset, dataset_info = tfds.load('malaria', with_info =True, as_supervised=True, shuffle_files=True, split=['train'])

dataset_info

# Taking a look at our data
for data in dataset[0].take(1):
  print(data)

def splits(dataset, TRAIN_RATIO, VAL_RATIO, TEST_RATIO):
  DATASET_SIZE = len(dataset)
  train_dataset = dataset.take(int(TRAIN_RATIO*DATASET_SIZE))

  val_dataset = dataset.skip(int(TRAIN_RATIO*DATASET_SIZE))
  val_dataset = val_dataset.take(int(VAL_RATIO*DATASET_SIZE))
  
  test_dataset = dataset.skip(int(VAL_RATIO*DATASET_SIZE))
  return train_dataset, val_dataset, test_dataset


# Split the DATASET into TRAIN, TEST, and VAL with TAKE and SKIP method
TRAIN_RATIO = 0.8
VAL_RATIO = 0.1
TEST_RATIO = 0.1 

train_dataset, val_dataset, test_dataset = splits(dataset[0], TRAIN_RATIO, VAL_RATIO, TEST_RATIO)

# Data Visualization

for i, (image, label) in enumerate(train_dataset.take(16)):
  ax = plt.subplot(4, 4, i+1)
  plt.imshow(image)
  plt.title(dataset_info.features['label'].int2str(label))


# Data Processing
// Resize (224)
// Normalization VS Standardize
// If the pixel values revolve around a particular mean value we choose to standardize.
// But, if the pixel values are very mostly different from eachother then we choose to normalize.

IM_SIZE = 224
def resize_rescale(image, label):
  return tf.image.resize(image, (IM_SIZE, IM_SIZE))/255.0, label


train_dataset = train_dataset.map(resize_rescale)
val_dataset = val_dataset.map(resize_rescale)
test_dataset = test_dataset.map(resize_rescale)

for image, label in train_dataset.take(1):
  print(image, label)


train_dataset = train_dataset.shuffle(buffer_size=8, reshuffle_each_iteration=True).batch(32).prefetch(tf.data.AUTOTUNE)
val_dataset = val_dataset.shuffle(buffer_size=8, reshuffle_each_iteration=True).batch(32).prefetch(tf.data.AUTOTUNE)

train_dataset
val_dataset


# Model Creation

// Build the Model

model = tf.keras.Sequential([
                              InputLayer(input_shape=(IM_SIZE, IM_SIZE, 3)),

                              Conv2D(filters=6, kernel_size=3, strides=1, padding='valid', activation='relu'),
                              BatchNormalization(),
                              MaxPool2D(pool_size=2, strides=2),

                              Conv2D(filters=16, kernel_size=3, strides=1, padding='valid', activation='relu'),
                              BatchNormalization(),
                              MaxPool2D(pool_size=2, strides=2),

                              Flatten(),

                              Dense(256, activation='relu'),
                              BatchNormalization(),
                              Dense(128, activation='relu'),
                              BatchNormalization(),
                              Dense(1, activation='sigmoid')

])

// Compile the Model

model.compile(optimizer= Adam(learning_rate=0.1),
              loss= BinaryCrossentropy(),
              metrics='accuracy')


// Fit the Model
history = model.fit(train_dataset, validation_data = val_dataset,epochs=10, verbose = 1)

# Visualize the Loss Curve

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(["train_loss", "val_loss"])
plt.show()

# Visualize the Accuracy Curve

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('epoch')
plt.legend(["train_accuracy", "val_accuracy"])
plt.show()


# Testing and Evaluating the Model

test_dataset = test_dataset.batch()
model.evaluate(test_dataset)
parasite_or_not(model.predict(test_dataset.take(1))[0][0])
def parasite_or_not(x):
  if(x<0.5):
    return str('P')
  else:
    return str('U')

  for i, (image, label) in enumerate(train_dataset.take(16)):
  ax = plt.subplot(3, 3, i+1)
  plt.imshow(image[0])
  plt.title(str(parasite_or_not(label.numpy()[0])) + ":" + str(parasite_or_not(model.predict(image)[0][0])))

  plt.axis('off')




# Now we are going to build and train our model by building it with functional API.

## Import Dependencies
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import tensorflow_datasets as tfds
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, InputLayer, BatchNormalization, Input
from tensorflow.keras.losses import BinaryCrossentropy
from tensorflow.keras.optimizers import Adam 
from tensorflow.keras.metrics import Accuracy

func_input = Input(shape = (IM_SIZE, IM_SIZE, 3), name = "Input Image")

x = Conv2D(filters = 6, kernel_size = 3, strides=1, padding='valid', activation = 'relu')(func_input)
x = BatchNormalization()(x)
x = MaxPool2D (pool_size = 2, strides= 2)(x)

x = Conv2D(filters = 16, kernel_size = 3, strides=1, padding='valid', activation = 'relu')(x)
x = BatchNormalization()(x)
output = MaxPool2D (pool_size = 2, strides= 2)(x)

feature_extractor_model = Model(func_input, output, name = "Feature_Extractor")
feature_extractor_model.summary()


func_input = Input(shape = (IM_SIZE, IM_SIZE, 3), name = "Input Image")
X = feature_extractor_model(func_input)

X = Flatten()(X)

X = Dense(256, activation='relu')(X)
X = BatchNormalization()(X)

X = Dense(128, activation='relu')(X)
X = BatchNormalization()(X)

func_output = Dense(1, activation='sigmoid')(X)

lenet_model_func = Model(func_input, func_output, name="Lenet_Model")
lenet_model_func.summary()

# Compile the Model
lenet_model_func.compile(optimizer = Adam(learning_rate= 0.01),
                     loss = BinaryCrossentropy(),
                     metrics = "accuracy')

history = lenet_model_func.fit(train_dataset, validation_data = val_dataset, epochs = 5, verbosse = 1)


# Now we are moving to build and train our model by Model Sub Classing.

## Import Dependencies
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import tensorflow_datasets as tfds
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Layer
from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, InputLayer, BatchNormalization, Input
from tensorflow.keras.losses import BinaryCrossentropy
from tensorflow.keras.optimizers import Adam 
from tensorflow.keras.metrics import Accuracy



# Build the Model with Model Subclassing

class FeatureExtractor(Layer):
  def __init__(self, filters, kernel_size, strides, padding, activation, pool_size, ): 
    super(FeatureExtractor, self).__init__()

    self.conv_1 = Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = padding, activation = activation)
    self.batch_1 = BatchNormalization()
    self.pool_1 = MaxPool2D(pool_size=pool_size, strides = 2*strides)

    self.conv_2 = Conv2D(filters = filters*2, kernel_size = kernel_size, strides = strides, padding = padding, activation = activation)
    self.batch_2 = BatchNormalization()
    self.pool_2 = MaxPool2D(pool_size = pool_size, strides = 2*strides)
  
  def call(self, X, training):
    
    X = self.conv_1(X)
    X = self.batch_1(X)
    X = self.pool_1(X)

    X = self.conv_2(X)
    X = self.batch_2(X)
    X = self.pool_2(X)

    return(X)

feature_sub_classed = FeatureExtractor(8, 3, 1, "valid", "relu", 2)


func_input = Input(shape = (IM_SIZE, IM_SIZE, 3), name = "Input Image")
X = feature_sub_classed(func_input)

X = Flatten()(X)

X = Dense(256, activation='relu')(X)
X = BatchNormalization()(X)

X = Dense(128, activation='relu')(X)
X = BatchNormalization()(X)

func_output = Dense(1, activation='sigmoid')(X)

lenet_model_func = Model(func_input, func_output, name="Lenet_Model")
lenet_model_func.summary()



## We created our feature extraction now we create the model providing the attribute layer or the sub layer as the feature extractor

class LenetModel(Model):
  def__init__(self, filters, kernel_size, strides, padding, activation, pool_size,):
    super(LenetModel, self).__init__()
    
    self.feature_extractor = FeatureExtractor(8, 3, 1, "valid", "relu", 2)

    self.flatten = Flatten()

    self.dense_1 = Dense(100, activation="relu")
    self.batch_1 = BatchNormalization()

    self.dense_2 = Dense(100, activation="relu")
    self.batch_2 = BatchNormalization()
    
    self.dense_3 = Dense(1, activation="sigmoid")

  def call(self, X, training):

    X = self.feature_extractor(X)
    X = self.flatten(X)
    X = self.dense_1(X)
    X = self.batch_1(X)
    X = self.dense_2(X)
    X = self.batch_2(X)
    X = self.dense_3(X)

    return X

lenet_sub_classed = LenetModel()
lenet_sub_classed(tf.zeros([1, 224, 224, 3])
lenet_sub_classed.summary()

# Compile the Model
lenet_sub_classed.compile(optimizer = Adam(learning_rate= 0.01),
                     loss = BinaryCrossentropy(),
                     metrics = "accuracy')

history = lenet_sub_classed.fit(train_dataset, validation_data = val_dataset, epochs = 5, verbosse = 1)
